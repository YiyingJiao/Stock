{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Yiying Jiao\n",
    "#Step 3 Use FinBert to calculate sentiment scores for each headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"22-23_main_df.csv.csv\")\n",
    "#get the correct format for date for both df\n",
    "meta_df['date'] = pd.to_datetime(meta_df['date'], format='%Y%m%d')\n",
    "\n",
    "meta_df = meta_df.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load FinBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract headline from URL\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "headlines = []\n",
    "urls = meta_df['url']\n",
    "\n",
    "for url in urls:\n",
    "    # Parse the path from the URL\n",
    "    path = urlparse(url).path  \n",
    "\n",
    "    # Remove leading numbers, trailing file extensions, or random alphanumeric codes\n",
    "    path = re.sub(r'^\\d{4}(/\\d{2})?(/\\d{2})?|news/\\d+', '', path)  # Remove dates or numbers before words\n",
    "    path = re.sub(r'/[A-Za-z0-9]+$', '', path)  # Remove trailing alphanumeric IDs\n",
    "\n",
    "    # Replace dashes/underscores with spaces\n",
    "    headline = re.sub(r\"[-_]\", \" \", path).strip()\n",
    "\n",
    "    # If headline is still empty, use 'Unknown'\n",
    "    if not headline:\n",
    "        headline = \"Unknown\"\n",
    "\n",
    "    headlines.append(headline)  \n",
    "\n",
    "# Add cleaned headlines to DataFrame\n",
    "meta_df['headline'] = headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        /business/2022/01/02/just how big in media doe...\n",
      "16       /pmn/business pmn/is apple worth 3 trillion bu...\n",
      "14       /dining around apple valleys pampa 172859691.html\n",
      "13                             //01/03/apple fast facts 2/\n",
      "12       /2022/01/03/analysis is apple worth 3 trillion...\n",
      "                               ...                        \n",
      "17034    /2023/12/29/news/florida family uses apple air...\n",
      "17035    /article/technology/tech news technology/tech ...\n",
      "17036    /2023/12/union minister chandrasekhar says rep...\n",
      "17029    /news/india/rajeev chandrashekhar rebuts washi...\n",
      "17058    /smart phone/apple cleared to resume flagship ...\n",
      "Name: headline, Length: 17059, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(meta_df['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date                                                url  \\\n",
      "0     2022-01-03  https://www.economist.com/business/2022/01/02/...   \n",
      "16    2022-01-03  https://montrealgazette.com/pmn/business-pmn/i...   \n",
      "14    2022-01-03  https://news.yahoo.com/dining-around-apple-val...   \n",
      "13    2022-01-03  https://ktvz.com/news/2022/01/03/apple-fast-fa...   \n",
      "12    2022-01-03  https://wtbx.com/2022/01/03/analysis-is-apple-...   \n",
      "...          ...                                                ...   \n",
      "17034 2023-12-29  https://nypost.com/2023/12/29/news/florida-fam...   \n",
      "17035 2023-12-29  https://indianexpress.com/article/technology/t...   \n",
      "17036 2023-12-29  https://yourstory.com:443/2023/12/union-minist...   \n",
      "17029 2023-12-29  https://economictimes.indiatimes.com/news/indi...   \n",
      "17058 2023-12-29  https://www.telecomlead.com/smart-phone/apple-...   \n",
      "\n",
      "                                                headline  \\\n",
      "0      /business/2022/01/02/just how big in media doe...   \n",
      "16     /pmn/business pmn/is apple worth 3 trillion bu...   \n",
      "14     /dining around apple valleys pampa 172859691.html   \n",
      "13                           //01/03/apple fast facts 2/   \n",
      "12     /2022/01/03/analysis is apple worth 3 trillion...   \n",
      "...                                                  ...   \n",
      "17034  /2023/12/29/news/florida family uses apple air...   \n",
      "17035  /article/technology/tech news technology/tech ...   \n",
      "17036  /2023/12/union minister chandrasekhar says rep...   \n",
      "17029  /news/india/rajeev chandrashekhar rebuts washi...   \n",
      "17058  /smart phone/apple cleared to resume flagship ...   \n",
      "\n",
      "                                  sentiment_probs  \n",
      "0        [0.9997911, 5.551799e-05, 0.00015333666]  \n",
      "16       [0.9999903, 2.0486498e-06, 7.691589e-06]  \n",
      "14     [0.99952173, 0.00013556411, 0.00034268052]  \n",
      "13     [0.99959517, 0.00018311969, 0.00022166295]  \n",
      "12      [0.9999638, 1.2771338e-06, 3.4898294e-05]  \n",
      "...                                           ...  \n",
      "17034   [0.99991006, 1.7728814e-06, 8.821566e-05]  \n",
      "17035   [0.9998932, 6.206162e-06, 0.000100637575]  \n",
      "17036    [0.9997653, 5.1404413e-06, 0.0002295739]  \n",
      "17029    [0.99999464, 5.362847e-07, 4.818177e-06]  \n",
      "17058       [0.15376472, 0.84392184, 0.002313433]  \n",
      "\n",
      "[17059 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to get sentiment probabilities\n",
    "def get_sentiment(headline):\n",
    "    inputs = tokenizer(headline, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits.detach().numpy()[0]\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))  # Softmax\n",
    "    return probs\n",
    "\n",
    "# Example DataFrame\n",
    "\n",
    "meta_df[\"sentiment_probs\"] = meta_df[\"headline\"].apply(get_sentiment)\n",
    "\n",
    "print(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break sentiment probs array into 3 elements\n",
    "meta_df[\"pos\"] = meta_df[\"sentiment_probs\"].apply(lambda x: x[0])\n",
    "meta_df[\"neut\"] = meta_df[\"sentiment_probs\"].apply(lambda x: x[1])\n",
    "meta_df[\"neg\"] = meta_df[\"sentiment_probs\"].apply(lambda x: x[2])\n",
    "meta_df[\"sentiment_score\"] = meta_df[\"sentiment_probs\"].apply(lambda x: -x[2] + x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df=meta_df.drop(['url','headline','sentiment_probs'], axis=1)\n",
    "\n",
    "probs_df.to_csv(\"/Users/jiao/projects/test22_23_probs_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
